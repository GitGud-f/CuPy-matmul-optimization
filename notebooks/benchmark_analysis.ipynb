{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68eba482",
   "metadata": {},
   "source": [
    " ## Environment Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd24c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Directories created: src, kernels, notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Create Directories\n",
    "os.makedirs('src', exist_ok=True)\n",
    "os.makedirs('kernels', exist_ok=True)\n",
    "os.makedirs('notebooks', exist_ok=True)\n",
    "\n",
    "print(\"✅ Directories created: src, kernels, notebooks\")\n",
    "\n",
    "with open('src/__init__.py', 'w') as f:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35361489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/utils.py\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def generate_matrices(n, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Generates two random N*N matrices A and B.\n",
    "    Using float32 is standard for GPU programming (single precision).\n",
    "    Args:\n",
    "        n: Size of the matrices (N x N).\n",
    "        dtype: Data type of the matrices (default: np.float32).\n",
    "    Returns: \n",
    "        Two N x N matrices A and B.\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.random.rand(n, n).astype(dtype)\n",
    "    B = np.random.rand(n, n).astype(dtype)\n",
    "    return A, B\n",
    "\n",
    "def check_correctness(target, reference, tolerance=1e-4):\n",
    "    \"\"\"\n",
    "    Compares two matrices using NumPy's allclose.\n",
    "    Args:\n",
    "        target: The matrix to test.\n",
    "        reference: The reference matrix.\n",
    "        tolerance: The tolerance for comparison (default: 1e-4).\n",
    "    Returns:\n",
    "        True if matrices are close within the given tolerance, False otherwise.\n",
    "    \"\"\"\n",
    "    if hasattr(target, 'get'): \n",
    "        target = target.get()\n",
    "    if hasattr(reference, 'get'): \n",
    "        reference = reference.get()\n",
    "    try:\n",
    "        np.testing.assert_allclose(target, reference, atol=tolerance, rtol=tolerance)\n",
    "        return True\n",
    "    except AssertionError:\n",
    "        return False\n",
    "\n",
    "def benchmark_function(func, name, *args):\n",
    "    \"\"\"\n",
    "    Benchmarks the execution time of a given function.\n",
    "    Args:\n",
    "        func: The function to benchmark.\n",
    "        name: Name of the function (for reporting).\n",
    "        *args: Arguments to pass to the function.\n",
    "    Returns:\n",
    "        A tuple containing the result of the function and the execution time in milliseconds.\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    result = func(*args)\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    execution_time_ms = (end_time - start_time) * 1000\n",
    "    print(f\"[{name}] Execution Time: {execution_time_ms:.4f} ms\")\n",
    "    return result, execution_time_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b591cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/cpu_baseline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/cpu_baseline.py\n",
    "import numpy as np\n",
    "\n",
    "def cpu_matmul(A, B):\n",
    "    \"\"\"\n",
    "    Standard Matrix Multiplication using Triple Nested Loops.\n",
    "    C[i][j] = sum(A[i][k] * B[k][j])\n",
    "    Args:\n",
    "        A: First input matrix.\n",
    "        B: Second input matrix.\n",
    "    Returns:\n",
    "        The resulting matrix after multiplication C = A * B.\n",
    "    \"\"\"\n",
    "\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    \n",
    "    rows_A, cols_A = A.shape\n",
    "    rows_B, cols_B = B.shape\n",
    "    \n",
    "    if cols_A != rows_B:\n",
    "        raise ValueError(\"Cannot multiply: Dimensions do not match.\")\n",
    "        \n",
    "    C = np.zeros((rows_A, cols_B), dtype=A.dtype)\n",
    "    \n",
    "    for i in range(rows_A):          \n",
    "        for j in range(cols_B):      \n",
    "            total = 0\n",
    "            for k in range(cols_A):  \n",
    "                total += A[i, k] * B[k, j]\n",
    "            C[i, j] = total\n",
    "            \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01297d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/gpu_ops.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/gpu_ops.py\n",
    "\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def transfer_to_gpu(A_host: np.ndarray, B_host: np.ndarray) -> tuple:\n",
    "    \n",
    "    \"\"\"\n",
    "    Transfers numpy arrays from Host (CPU) to Device (GPU).\n",
    "    Args:\n",
    "        A_host: First input matrix on host (CPU).\n",
    "        B_host: Second input matrix on host (CPU).\n",
    "    Returns:\n",
    "        Two matrices A and B on device (GPU).\n",
    "    \"\"\"\n",
    "    A_gpu = cp.asarray(A_host)\n",
    "    B_gpu = cp.asarray(B_host)\n",
    "    return A_gpu, B_gpu\n",
    "\n",
    "def cupy_matmul_library(A_gpu: cp.ndarray, B_gpu: cp.ndarray) -> cp.ndarray:\n",
    "    \"\"\"\n",
    "    Performs Matrix Multiplication using CuPy's optimized library.\n",
    "    Args:\n",
    "        A_gpu: First input matrix on device (GPU).\n",
    "        B_gpu: Second input matrix on device (GPU).\n",
    "    Returns:    \n",
    "        The resulting matrix after multiplication C = A * B on device (GPU).\n",
    "    \"\"\"\n",
    "    return cp.matmul(A_gpu, B_gpu)\n",
    "\n",
    "def run_custom_kernel(kernel_source: str, function_name: str, grid: tuple, block: tuple, args: tuple):\n",
    "    \"\"\"\n",
    "    Compiles and executes a raw CUDA kernel.\n",
    "    Args:\n",
    "        kernel_source: The source code of the CUDA kernel as a string.\n",
    "        function_name: The name of the kernel function to execute.\n",
    "        grid: The grid dimensions for kernel launch.\n",
    "        block: The block dimensions for kernel launch.\n",
    "        args: The arguments to pass to the kernel.\n",
    "    \"\"\"\n",
    "    module = cp.RawModule(code=kernel_source)\n",
    "    kernel = module.get_function(function_name)\n",
    "    kernel(grid, block, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc29317c",
   "metadata": {},
   "source": [
    "## CPU Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33ab143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully.\n",
      "Part 1: CPU Baseline Benchmark (N=512)\n",
      "[CPU Naive] Execution Time: 52608.5295 ms\n",
      "PASS: CPU implementation matches NumPy reference.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from src.utils import generate_matrices, check_correctness, benchmark_function\n",
    "from src.cpu_baseline import cpu_matmul\n",
    "\n",
    "print(\"Modules imported successfully.\")\n",
    "\n",
    "\n",
    "N = 512\n",
    "print(f\"Part 1: CPU Baseline Benchmark (N={N})\")\n",
    "\n",
    "A_host, B_host = generate_matrices(N)\n",
    "\n",
    "\n",
    "C_cpu, time_cpu = benchmark_function(cpu_matmul, \"CPU Naive\", A_host, B_host)\n",
    "\n",
    "C_ref = np.dot(A_host, B_host)\n",
    "\n",
    "if check_correctness(C_cpu, C_ref):\n",
    "    print(\"PASS: CPU implementation matches NumPy reference.\")\n",
    "else:\n",
    "    print(\"FAIL: CPU implementation is incorrect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c882e3",
   "metadata": {},
   "source": [
    "## GPU using CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce70e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2: CuPy (GPU) Implementation\n",
      "\n",
      "Experiment A: Small Matrix (N=512)\n",
      "Transferring data to GPU... Done.\n",
      "Warming up GPU... Done.\n",
      "[CuPy Library] Execution Time: 0.2427 ms\n",
      "PASS: CuPy result matches Reference.\n",
      "Speedup vs CPU: 216806.49x\n",
      "\n",
      "--- Experiment B: Large Matrix (N=2000) ---\n",
      "[CuPy (N=2000)] Execution Time: 0.5399 ms\n",
      "Note: A CPU naive loop for N=2000 would take hours.\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "from src.gpu_ops import transfer_to_gpu, cupy_matmul_library\n",
    "\n",
    "print(\"Part 2: CuPy (GPU) Implementation\")\n",
    "\n",
    "print(f\"\\nExperiment A: Small Matrix (N={N})\")\n",
    "\n",
    "\n",
    "print(\"Transferring data to GPU...\", end=\" \")\n",
    "A_gpu, B_gpu = transfer_to_gpu(A_host, B_host) \n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Warming up GPU...\", end=\" \")\n",
    "cupy_matmul_library(A_gpu, B_gpu)\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "print(\"Done.\")\n",
    "\n",
    "C_gpu, time_gpu = benchmark_function(cupy_matmul_library, \"CuPy Library\", A_gpu, B_gpu)\n",
    "\n",
    "\n",
    "if check_correctness(C_gpu, C_ref):\n",
    "    print(\"PASS: CuPy result matches Reference.\")\n",
    "    print(f\"Speedup vs CPU: {time_cpu / time_gpu:.2f}x\")\n",
    "else:\n",
    "    print(\"FAIL: CuPy result incorrect.\")\n",
    "\n",
    "\n",
    "N_large = 2000\n",
    "print(f\"\\nExperiment B: Large Matrix (N={N_large})\")\n",
    "\n",
    "A_large, B_large = generate_matrices(N_large)\n",
    "A_large_gpu, B_large_gpu = transfer_to_gpu(A_large, B_large)\n",
    "\n",
    "C_large_gpu, time_large_gpu = benchmark_function(cupy_matmul_library, f\"CuPy (N={N_large})\", A_large_gpu, B_large_gpu)\n",
    "\n",
    "print(f\"Note: A CPU naive loop for N={N_large} would take hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f226e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
